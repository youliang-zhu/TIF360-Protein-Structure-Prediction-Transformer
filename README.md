Protein Structure Prediction with Transformer
=============================================

This project offers a deep learning pipeline for **protein structure prediction** using a **Transformer architecture**. It covers everything from data preprocessing to model training, validation, and visualization. The entire pipeline is built and optimized for execution within **Google Colab**.

* * *

Project Structure
-----------------

    .
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ 01_protein_pdb_id                    # List of protein PDB IDs
    â”‚   â”œâ”€â”€ 02_downloaded_filtered_protein_data  # (Generated by user) Downloaded and filtered protein data
    â”‚   â”œâ”€â”€ 03_train_valid_dataset_and_statics   # (Generated by user) Processed training and validation datasets
    â”œâ”€â”€ outputs/
    â”‚   â”œâ”€â”€ models/                              # Trained model weights
    â”‚   â”œâ”€â”€ plots/                               # Visualization plots
    â”œâ”€â”€ src/ProteinPredictionTransformer         # Core Transformer model and training notebooks
    â”œâ”€â”€ README.md
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ .gitignore

ðŸš€ Get Started
--------------

This project is designed to run in **Google Colab**. To begin, follow these steps:

### 1. Install Dependencies

In your Colab notebook, install the necessary packages by running the following command:
    !pip install -r requirements.txt

### 2. Prepare Your Data

The data folder contains a list of protein IDs (`01_protein_pdb_id`). However, the actual protein data and processed datasets (`02_downloaded_filtered_protein_data` and `03_train_valid_dataset_and_statics`) are not included due to file size limits.

You'll need to generate these datasets yourself using the provided notebooks in the `utils_data_preprocess` directory:

* `02_download_with_id_and_filter.ipynb`: Use this to download and filter protein data based on the provided IDs.
* `03_preprocess_and_split_train_valid_dataset.ipynb`: This notebook will process the raw data and split it into training and validation sets.

### 3. Organize Files in Google Drive

After generating your datasets, upload them to your Google Drive. Make sure to adjust the file paths in your Colab notebooks to correctly point to these locations in your Drive.

### 4. Run the Model

Navigate to the `src/ProteinPredictionTransformer` directory in your Colab environment. Here, you'll find the notebooks to run the Transformer-based protein structure prediction model, including training and testing phases.
Use our trained model

---------------------

## ðŸ§  Use our trained model

You can find `best_model.pth` in the `outputs/models` folder. Simply configure the path in `src/ProteinPredictionTransformer` to directly use our trained model weights for prediction. You can debug the model's prediction performance on individual samples in the training set. One example is shown in the following figure:

![Alt text](outputs/plots/3D%20structure%20sample%201.png)
